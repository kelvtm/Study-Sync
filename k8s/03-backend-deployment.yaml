# ============================================
# Backend Deployment
# ============================================
#
# CONCEPT: Deployment manages ReplicaSets, which manage Pods
#
# Deployment → ReplicaSet → Pods
#
# WHY USE DEPLOYMENTS?
# 1. Declarative updates (change image version in YAML)
# 2. Rolling updates (zero downtime)
# 3. Rollback capability
# 4. Self-healing (auto-restart failed Pods)
# 5. Scaling (horizontally scale Pods)
#
# DEPLOYMENT STRATEGIES:
# - RollingUpdate: Update Pods gradually (default)
# - Recreate: Kill all Pods, then create new ones (downtime)
# ============================================

apiVersion: apps/v1
kind: Deployment
metadata:
  name: studysync-backend
  namespace: studysync-dev
  labels:
    app: studysync
    component: backend
    version: v1.0.0
  annotations:
    description: "StudySync Backend API Server"
spec:
  # ============================================
  # REPLICAS: Number of Pod copies to run
  # ============================================
  replicas: 3 # Run 3 backend Pods for high availability

  # ============================================
  # SELECTOR: How Deployment finds its Pods
  # ============================================
  selector:
    matchLabels:
      app: studysync
      component: backend

  # ============================================
  # STRATEGY: How to update Pods
  # ============================================
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1 # Max 1 extra Pod during update
      maxUnavailable: 1 # Max 1 Pod down during update

  # LEARNING NOTE:
  # With 3 replicas, maxSurge=1, maxUnavailable=1:
  # - During update, max 4 Pods running (3 + 1)
  # - At least 2 Pods always running (3 - 1)
  # - Updates happen one at a time

  # ============================================
  # TEMPLATE: Pod specification
  # ============================================
  template:
    metadata:
      labels:
        app: studysync
        component: backend
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "3000"
        prometheus.io/path: "/metrics"

    spec:
      # ============================================
      # IMAGE PULL SECRETS (if using private registry)
      # ============================================
      imagePullSecrets:
        - name: dockerhub-secret

      # ============================================
      # CONTAINERS
      # ============================================
      containers:
        - name: backend
          image: kelvtmoni/studysync-backend:latest
          imagePullPolicy: IfNotPresent # Use local image if available

          # LEARNING NOTE: Image Pull Policies
          # - Always: Pull image every time (good for :latest tag)
          # - IfNotPresent: Pull only if not cached (good for specific versions)
          # - Never: Never pull, use cached only

          ports:
            - name: http
              containerPort: 3000
              protocol: TCP

          # ============================================
          # ENVIRONMENT VARIABLES
          # ============================================
          # Method 1: From ConfigMap
          envFrom:
            - configMapRef:
                name: studysync-backend-config

            # Method 2: From Secrets
            - secretRef:
                name: studysync-secrets

          # Method 3: Individual values
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP

          # ============================================
          # RESOURCE REQUESTS & LIMITS
          # ============================================
          # CONCEPT: Tell Kubernetes how much CPU/memory needed
          #
          # REQUESTS: Minimum guaranteed resources
          # - Scheduler uses this to decide which node
          # - Pod won't start if node doesn't have these resources
          #
          # LIMITS: Maximum allowed resources
          # - Pod gets killed if exceeds memory limit (OOMKilled)
          # - Pod gets throttled if exceeds CPU limit
          # ============================================
          resources:
            requests:
              memory: "256Mi" # Need at least 256MB
              cpu: "250m" # Need at least 0.25 CPU cores
            limits:
              memory: "512Mi" # Max 512MB (killed if exceeded)
              cpu: "500m" # Max 0.5 CPU cores (throttled if exceeded)

          # LEARNING NOTE: CPU Units
          # 1 CPU = 1000m (millicores)
          # 250m = 0.25 CPU = 1/4 of a CPU core
          # 1000m = 1 CPU = 1 full CPU core

          # ============================================
          # LIVENESS PROBE
          # ============================================
          # CONCEPT: Is the container alive and healthy?
          # If fails → Kubernetes RESTARTS the container
          #
          # USE CASE: Detect deadlocks, infinite loops
          # ============================================
          livenessProbe:
            httpGet:
              path: /api/health
              port: 3000
              httpHeaders:
                - name: X-Health-Check
                  value: "liveness"
            initialDelaySeconds: 30 # Wait 30s after start
            periodSeconds: 10 # Check every 10s
            timeoutSeconds: 5 # Timeout after 5s
            successThreshold: 1 # 1 success = healthy
            failureThreshold: 3 # 3 failures = restart

          # ============================================
          # READINESS PROBE
          # ============================================
          # CONCEPT: Is the container ready to accept traffic?
          # If fails → Kubernetes REMOVES from Service load balancer
          # (doesn't restart container)
          #
          # USE CASE: Wait for DB connection, warm up caches
          # ============================================
          readinessProbe:
            httpGet:
              path: /api/health
              port: 3000
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 3

          # ============================================
          # STARTUP PROBE (Optional)
          # ============================================
          # CONCEPT: Is the container starting up?
          # Used for slow-starting containers
          # Liveness/Readiness probes disabled until startup succeeds
          # ============================================
          startupProbe:
            httpGet:
              path: /api/health
              port: 3000
            initialDelaySeconds: 0
            periodSeconds: 5
            timeoutSeconds: 3
            successThreshold: 1
            failureThreshold: 30 # Allow 30 * 5s = 150s to start

          # ============================================
          # VOLUME MOUNTS (if needed)
          # ============================================
          # volumeMounts:
          # - name: config-volume
          #   mountPath: /etc/config
          # - name: secrets-volume
          #   mountPath: /etc/secrets
          #   readOnly: true

      # ============================================
      # VOLUMES (if needed)
      # ============================================
      # volumes:
      # - name: config-volume
      #   configMap:
      #     name: studysync-backend-config
      # - name: secrets-volume
      #   secret:
      #     secretName: studysync-secrets

      # ============================================
      # POD SETTINGS
      # ============================================
      restartPolicy: Always # Always restart if container fails

      # DNS Policy
      dnsPolicy: ClusterFirst

      # Security Context (Optional - for production)
      # securityContext:
      #   runAsNonRoot: true
      #   runAsUser: 1000
      #   fsGroup: 2000

      # Termination Grace Period
      terminationGracePeriodSeconds: 30
# ============================================
# COMMANDS:
# ============================================
#
# Apply Deployment:
#   kubectl apply -f 03-backend-deployment.yaml
#
# Get Deployments:
#   kubectl get deployments -n studysync-dev
#   kubectl get deploy -n studysync-dev  # Short form
#
# Describe Deployment:
#   kubectl describe deployment studysync-backend -n studysync-dev
#
# View Pods created by Deployment:
#   kubectl get pods -n studysync-dev -l app=studysync,component=backend
#
# Scale Deployment:
#   kubectl scale deployment studysync-backend --replicas=5 -n studysync-dev
#
# Update Image (Rolling Update):
#   kubectl set image deployment/studysync-backend \
#     backend=kelvtmoni/studysync-backend:v1.0.1 \
#     -n studysync-dev
#
# Check Rollout Status:
#   kubectl rollout status deployment/studysync-backend -n studysync-dev
#
# View Rollout History:
#   kubectl rollout history deployment/studysync-backend -n studysync-dev
#
# Rollback to Previous Version:
#   kubectl rollout undo deployment/studysync-backend -n studysync-dev
#
# Rollback to Specific Revision:
#   kubectl rollout undo deployment/studysync-backend --to-revision=2 -n studysync-dev
#
# Pause Rollout (stop rolling update):
#   kubectl rollout pause deployment/studysync-backend -n studysync-dev
#
# Resume Rollout:
#   kubectl rollout resume deployment/studysync-backend -n studysync-dev
#
# View Logs from all Pods:
#   kubectl logs -f deployment/studysync-backend -n studysync-dev
#
# Delete Deployment:
#   kubectl delete deployment studysync-backend -n studysync-dev
# ============================================

# ============================================
# DEPLOYMENT LIFECYCLE:
# ============================================
#
# 1. Create Deployment
#    kubectl apply -f deployment.yaml
#    → Deployment created
#    → ReplicaSet created
#    → 3 Pods created
#
# 2. Update Image
#    kubectl set image deployment/backend backend=new:version
#    → New ReplicaSet created
#    → New Pods created gradually
#    → Old Pods terminated gradually
#    → Old ReplicaSet kept (for rollback)
#
# 3. Scale
#    kubectl scale deployment/backend --replicas=5
#    → 2 more Pods created
#    → Total: 5 Pods
#
# 4. Rollback
#    kubectl rollout undo deployment/backend
#    → Switch back to old ReplicaSet
#    → Old Pods recreated
#    → New Pods terminated
# ============================================
